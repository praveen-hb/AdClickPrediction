{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/regularization-techniques/test.csv\n/kaggle/input/regularization-techniques/train.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train= pd.read_csv('/kaggle/input/regularization-techniques/train.csv')\ndf_test = pd.read_csv('/kaggle/input/regularization-techniques/test.csv')","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_values=df_train.values\ntest_values = df_test.values","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(train_values[:,1:])\nY_train = np.array(train_values[:,0])\nX_test = np.array(test_values[:,1:])\nY_test = np.array(test_values[:,0])","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Augumentation (Rescaling)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X_train.reshape(-1,28,28,1)/255.0\nX_train.shape","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"(27455, 28, 28, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = X_test.reshape(-1,28,28,1)/255.0\nX_test.shape","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"(7172, 28, 28, 1)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**Importing Libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.utils.np_utils import to_categorical \n","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_of_labels = np.max(Y_train)\nnumber_of_labels","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"24"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":" **Model without regularization techniques**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(INPUT_SHAPE):\n    model = Sequential()\n    model.add(Conv2D(filters = 8, kernel_size=(3, 3),strides=(1,1),padding=\"valid\", input_shape=INPUT_SHAPE))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding=\"same\"))\n\n    model.add(Conv2D(filters = 16, kernel_size=(3, 3),strides=(1,1),padding=\"valid\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding=\"same\"))\n\n    model.add(Conv2D(filters = 32, kernel_size=(3, 3),strides=(1,1),padding=\"valid\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    \n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(number_of_labels+1, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    model.summary()\n    return model\n    ","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train[0].shape","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"(28, 28, 1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=create_model(X_train[0].shape)","execution_count":12,"outputs":[{"output_type":"stream","text":"Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 26, 26, 8)         80        \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 26, 26, 8)         32        \n_________________________________________________________________\nactivation (Activation)      (None, 26, 26, 8)         0         \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 13, 13, 8)         0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 11, 11, 16)        1168      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 11, 11, 16)        64        \n_________________________________________________________________\nactivation_1 (Activation)    (None, 11, 11, 16)        0         \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 6, 6, 16)          0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 4, 4, 32)          4640      \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 4, 4, 32)          128       \n_________________________________________________________________\nactivation_2 (Activation)    (None, 4, 4, 32)          0         \n_________________________________________________________________\nflatten (Flatten)            (None, 512)               0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               65664     \n_________________________________________________________________\ndense_1 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_2 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_3 (Dense)              (None, 64)                4160      \n_________________________________________________________________\ndense_4 (Dense)              (None, 32)                2080      \n_________________________________________________________________\ndense_5 (Dense)              (None, 32)                1056      \n_________________________________________________________________\ndense_6 (Dense)              (None, 25)                825       \n=================================================================\nTotal params: 104,665\nTrainable params: 104,553\nNon-trainable params: 112\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"to_categorical(Y_train,number_of_labels+1).shape","execution_count":13,"outputs":[{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"(27455, 25)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,to_categorical(Y_train,number_of_labels+1),batch_size=32,epochs=5,validation_split=0.2)","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n687/687 [==============================] - 4s 5ms/step - loss: 0.6504 - accuracy: 0.7932 - val_loss: 0.0347 - val_accuracy: 0.9927\nEpoch 2/5\n687/687 [==============================] - 3s 4ms/step - loss: 0.0462 - accuracy: 0.9861 - val_loss: 0.0060 - val_accuracy: 0.9989\nEpoch 3/5\n687/687 [==============================] - 3s 4ms/step - loss: 0.0160 - accuracy: 0.9957 - val_loss: 0.7242 - val_accuracy: 0.8192\nEpoch 4/5\n687/687 [==============================] - 3s 5ms/step - loss: 0.0349 - accuracy: 0.9903 - val_loss: 0.0064 - val_accuracy: 0.9989\nEpoch 5/5\n687/687 [==============================] - 3s 4ms/step - loss: 0.0011 - accuracy: 0.9998 - val_loss: 6.3784e-04 - val_accuracy: 0.9998\n","name":"stdout"},{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f90432d65d0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss,accuracy=model.evaluate(X_test,to_categorical(Y_test,number_of_labels+1))\nprint(\"Accuracy of the model without regularization: \"+ str(accuracy))","execution_count":15,"outputs":[{"output_type":"stream","text":"225/225 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.8833\nAccuracy of the model without regularization: 0.8832961320877075\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"L1 Regularization"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import regularizers","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_with_L1(INPUT_SHAPE):\n    model = Sequential()\n    model.add(Conv2D(filters = 8, kernel_size=(3, 3),strides=(1,1),padding=\"valid\", input_shape=INPUT_SHAPE))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding=\"same\"))\n\n    model.add(Conv2D(filters = 16, kernel_size=(3, 3),strides=(1,1),padding=\"valid\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding=\"same\"))\n\n    model.add(Conv2D(filters = 32, kernel_size=(3, 3),strides=(1,1),kernel_regularizer=regularizers.l2(0.01),padding=\"valid\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    \n    model.add(Flatten())\n    model.add(Dense(128,kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n    model.add(Dense(128,kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(64,kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dense(32,kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n    model.add(Dense(number_of_labels+1, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    model.summary()\n    return model","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=create_model_with_L1(X_train[0].shape)","execution_count":18,"outputs":[{"output_type":"stream","text":"Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_3 (Conv2D)            (None, 26, 26, 8)         80        \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 26, 26, 8)         32        \n_________________________________________________________________\nactivation_3 (Activation)    (None, 26, 26, 8)         0         \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 13, 13, 8)         0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 11, 11, 16)        1168      \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 11, 11, 16)        64        \n_________________________________________________________________\nactivation_4 (Activation)    (None, 11, 11, 16)        0         \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, 6, 6, 16)          0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 4, 4, 32)          4640      \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 4, 4, 32)          128       \n_________________________________________________________________\nactivation_5 (Activation)    (None, 4, 4, 32)          0         \n_________________________________________________________________\nflatten_1 (Flatten)          (None, 512)               0         \n_________________________________________________________________\ndense_7 (Dense)              (None, 128)               65664     \n_________________________________________________________________\ndense_8 (Dense)              (None, 128)               16512     \n_________________________________________________________________\ndense_9 (Dense)              (None, 64)                8256      \n_________________________________________________________________\ndense_10 (Dense)             (None, 64)                4160      \n_________________________________________________________________\ndense_11 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndense_12 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_13 (Dense)             (None, 25)                825       \n=================================================================\nTotal params: 104,665\nTrainable params: 104,553\nNon-trainable params: 112\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,to_categorical(Y_train,number_of_labels+1),batch_size=32,epochs=5,validation_split=0.2)","execution_count":19,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n687/687 [==============================] - 3s 5ms/step - loss: 6.5969 - accuracy: 0.0456 - val_loss: 3.2842 - val_accuracy: 0.0419\nEpoch 2/5\n687/687 [==============================] - 3s 5ms/step - loss: 3.2824 - accuracy: 0.0464 - val_loss: 3.2816 - val_accuracy: 0.0441\nEpoch 3/5\n687/687 [==============================] - 3s 5ms/step - loss: 3.2803 - accuracy: 0.0441 - val_loss: 3.2796 - val_accuracy: 0.0479\nEpoch 4/5\n687/687 [==============================] - 3s 5ms/step - loss: 3.2801 - accuracy: 0.0439 - val_loss: 3.2803 - val_accuracy: 0.0406\nEpoch 5/5\n687/687 [==============================] - 3s 5ms/step - loss: 3.2797 - accuracy: 0.0442 - val_loss: 3.2796 - val_accuracy: 0.0479\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f9042b01cd0>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss,accuracy=model.evaluate(X_test,to_categorical(Y_test,number_of_labels+1))\nprint(\"Accuracy of the model with L1 Regularization: \"+ str(accuracy))","execution_count":20,"outputs":[{"output_type":"stream","text":"225/225 [==============================] - 1s 3ms/step - loss: 3.3034 - accuracy: 0.0201\nAccuracy of the model with L1 Regularization: 0.020078081637620926\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"***L2 Regularization with Dropout***"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_with_L2_Dropout(INPUT_SHAPE):\n    model = Sequential()\n    model.add(Conv2D(filters = 8, kernel_size=(3, 3),strides=(1,1),padding=\"valid\", input_shape=INPUT_SHAPE))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding=\"same\"))\n\n    model.add(Conv2D(filters = 16, kernel_size=(3, 3),strides=(1,1),padding=\"valid\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding=\"same\"))\n\n    model.add(Conv2D(filters = 32, kernel_size=(3, 3),strides=(1,1),kernel_regularizer=regularizers.l2(0.01),padding=\"valid\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    \n    model.add(Flatten())\n    model.add(Dense(128,kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n    model.add(Dense(128,kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(64,kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(32,kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n    model.add(Dense(number_of_labels+1, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    model.summary()\n    return model","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=create_model_with_L2_Dropout(X_train[0].shape)","execution_count":22,"outputs":[{"output_type":"stream","text":"Model: \"sequential_2\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_6 (Conv2D)            (None, 26, 26, 8)         80        \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 26, 26, 8)         32        \n_________________________________________________________________\nactivation_6 (Activation)    (None, 26, 26, 8)         0         \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, 13, 13, 8)         0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, 11, 11, 16)        1168      \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, 11, 11, 16)        64        \n_________________________________________________________________\nactivation_7 (Activation)    (None, 11, 11, 16)        0         \n_________________________________________________________________\nmax_pooling2d_5 (MaxPooling2 (None, 6, 6, 16)          0         \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, 4, 4, 32)          4640      \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, 4, 4, 32)          128       \n_________________________________________________________________\nactivation_8 (Activation)    (None, 4, 4, 32)          0         \n_________________________________________________________________\ndropout (Dropout)            (None, 4, 4, 32)          0         \n_________________________________________________________________\nflatten_2 (Flatten)          (None, 512)               0         \n_________________________________________________________________\ndense_14 (Dense)             (None, 128)               65664     \n_________________________________________________________________\ndense_15 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_16 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndense_17 (Dense)             (None, 64)                4160      \n_________________________________________________________________\ndense_18 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_19 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_20 (Dense)             (None, 25)                825       \n=================================================================\nTotal params: 104,665\nTrainable params: 104,553\nNon-trainable params: 112\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,to_categorical(Y_train,number_of_labels+1),batch_size=32,epochs=5,validation_split=0.2)","execution_count":23,"outputs":[{"output_type":"stream","text":"Epoch 1/5\n687/687 [==============================] - 4s 5ms/step - loss: 2.6574 - accuracy: 0.3922 - val_loss: 1.3134 - val_accuracy: 0.7164\nEpoch 2/5\n687/687 [==============================] - 3s 5ms/step - loss: 1.2290 - accuracy: 0.7360 - val_loss: 0.8542 - val_accuracy: 0.8579\nEpoch 3/5\n687/687 [==============================] - 4s 6ms/step - loss: 0.8987 - accuracy: 0.8595 - val_loss: 0.6021 - val_accuracy: 0.9636\nEpoch 4/5\n687/687 [==============================] - 3s 5ms/step - loss: 0.7689 - accuracy: 0.9009 - val_loss: 0.5022 - val_accuracy: 0.9863\nEpoch 5/5\n687/687 [==============================] - 4s 5ms/step - loss: 0.6593 - accuracy: 0.9247 - val_loss: 0.4601 - val_accuracy: 0.9871\n","name":"stdout"},{"output_type":"execute_result","execution_count":23,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f90423c6910>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss,accuracy=model.evaluate(X_test,to_categorical(Y_test,number_of_labels+1))\nprint(\"Accuracy of the model with L2 regularization and Dropout: \"+ str(accuracy))","execution_count":24,"outputs":[{"output_type":"stream","text":"225/225 [==============================] - 1s 3ms/step - loss: 0.8687 - accuracy: 0.8769\nAccuracy of the model with L2 regularization and Dropout: 0.8768823146820068\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**Model with L1,L2,Dropout and EarlyStopping**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model_with_L1_L2_Dropout_EarlyStopping(INPUT_SHAPE):\n    model = Sequential()\n    model.add(Conv2D(filters = 8, kernel_size=(3, 3),strides=(1,1),padding=\"valid\", input_shape=INPUT_SHAPE))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding=\"same\"))\n\n    model.add(Conv2D(filters = 16, kernel_size=(3, 3),strides=(1,1),padding=\"valid\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2),padding=\"same\"))\n\n    model.add(Conv2D(filters = 32, kernel_size=(3, 3),strides=(1,1),kernel_regularizer=regularizers.l1(0.01),padding=\"valid\"))\n    model.add(BatchNormalization())\n    model.add(Activation('relu'))\n    model.add(Dropout(0.2))\n    \n    model.add(Flatten())\n    model.add(Dense(128,kernel_regularizer=regularizers.l1(0.01), activation='relu'))\n    model.add(Dense(128,kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dense(64,kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n    model.add(Dense(32, activation='relu'))\n    model.add(Dropout(0.3))\n    model.add(Dense(32,kernel_regularizer=regularizers.l2(0.01), activation='relu'))\n    model.add(Dense(number_of_labels+1, activation='softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    model.summary()\n    return model","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=create_model_with_L1_L2_Dropout_EarlyStopping(X_train[0].shape)","execution_count":26,"outputs":[{"output_type":"stream","text":"Model: \"sequential_3\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_9 (Conv2D)            (None, 26, 26, 8)         80        \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, 26, 26, 8)         32        \n_________________________________________________________________\nactivation_9 (Activation)    (None, 26, 26, 8)         0         \n_________________________________________________________________\nmax_pooling2d_6 (MaxPooling2 (None, 13, 13, 8)         0         \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, 11, 11, 16)        1168      \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, 11, 11, 16)        64        \n_________________________________________________________________\nactivation_10 (Activation)   (None, 11, 11, 16)        0         \n_________________________________________________________________\nmax_pooling2d_7 (MaxPooling2 (None, 6, 6, 16)          0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, 4, 4, 32)          4640      \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, 4, 4, 32)          128       \n_________________________________________________________________\nactivation_11 (Activation)   (None, 4, 4, 32)          0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 4, 4, 32)          0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 512)               0         \n_________________________________________________________________\ndense_21 (Dense)             (None, 128)               65664     \n_________________________________________________________________\ndense_22 (Dense)             (None, 128)               16512     \n_________________________________________________________________\ndense_23 (Dense)             (None, 64)                8256      \n_________________________________________________________________\ndense_24 (Dense)             (None, 64)                4160      \n_________________________________________________________________\ndense_25 (Dense)             (None, 32)                2080      \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 32)                0         \n_________________________________________________________________\ndense_26 (Dense)             (None, 32)                1056      \n_________________________________________________________________\ndense_27 (Dense)             (None, 25)                825       \n=================================================================\nTotal params: 104,665\nTrainable params: 104,553\nNon-trainable params: 112\n_________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import RMSprop,SGD,Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(r'C:\\Label.h5',\n                             monitor='val_loss',\n                             mode='min',\n                             save_best_only=True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor='val_loss',\n                          min_delta=0,\n                          patience=3,\n                          verbose=1,\n                          restore_best_weights=True\n                          )\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.2,\n                              patience=3,\n                              verbose=1,\n                              min_delta=0.0001)\n\ncallbacks = [earlystop,checkpoint,reduce_lr]","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,to_categorical(Y_train,number_of_labels+1),\n          batch_size=32,epochs=10,\n          validation_split=0.2,\n          callbacks=callbacks)","execution_count":28,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n682/687 [============================>.] - ETA: 0s - loss: 5.0783 - accuracy: 0.1031\nEpoch 00001: val_loss improved from inf to 3.02185, saving model to C:\\Label.h5\n687/687 [==============================] - 4s 6ms/step - loss: 5.0627 - accuracy: 0.1034 - val_loss: 3.0218 - val_accuracy: 0.1064\nEpoch 2/10\n676/687 [============================>.] - ETA: 0s - loss: 2.5879 - accuracy: 0.1681\nEpoch 00002: val_loss improved from 3.02185 to 2.38188, saving model to C:\\Label.h5\n687/687 [==============================] - 4s 5ms/step - loss: 2.5859 - accuracy: 0.1685 - val_loss: 2.3819 - val_accuracy: 0.1991\nEpoch 3/10\n682/687 [============================>.] - ETA: 0s - loss: 2.4151 - accuracy: 0.1957\nEpoch 00003: val_loss improved from 2.38188 to 2.22159, saving model to C:\\Label.h5\n687/687 [==============================] - 4s 5ms/step - loss: 2.4145 - accuracy: 0.1963 - val_loss: 2.2216 - val_accuracy: 0.2388\nEpoch 4/10\n682/687 [============================>.] - ETA: 0s - loss: 2.3436 - accuracy: 0.2136\nEpoch 00004: val_loss did not improve from 2.22159\n687/687 [==============================] - 3s 5ms/step - loss: 2.3426 - accuracy: 0.2141 - val_loss: 2.2254 - val_accuracy: 0.2420\nEpoch 5/10\n676/687 [============================>.] - ETA: 0s - loss: 2.2653 - accuracy: 0.2439\nEpoch 00005: val_loss did not improve from 2.22159\n687/687 [==============================] - 3s 5ms/step - loss: 2.2651 - accuracy: 0.2438 - val_loss: 2.4830 - val_accuracy: 0.2154\nEpoch 6/10\n686/687 [============================>.] - ETA: 0s - loss: 2.2079 - accuracy: 0.2540\nEpoch 00006: val_loss improved from 2.22159 to 2.15566, saving model to C:\\Label.h5\n687/687 [==============================] - 4s 5ms/step - loss: 2.2079 - accuracy: 0.2540 - val_loss: 2.1557 - val_accuracy: 0.2544\nEpoch 7/10\n683/687 [============================>.] - ETA: 0s - loss: 2.1363 - accuracy: 0.2793\nEpoch 00007: val_loss improved from 2.15566 to 2.13439, saving model to C:\\Label.h5\n687/687 [==============================] - 3s 5ms/step - loss: 2.1367 - accuracy: 0.2794 - val_loss: 2.1344 - val_accuracy: 0.2894\nEpoch 8/10\n677/687 [============================>.] - ETA: 0s - loss: 2.0961 - accuracy: 0.2976\nEpoch 00008: val_loss did not improve from 2.13439\n687/687 [==============================] - 3s 5ms/step - loss: 2.0965 - accuracy: 0.2976 - val_loss: 3.4826 - val_accuracy: 0.2142\nEpoch 9/10\n682/687 [============================>.] - ETA: 0s - loss: 2.0357 - accuracy: 0.3247\nEpoch 00009: val_loss improved from 2.13439 to 1.99790, saving model to C:\\Label.h5\n687/687 [==============================] - 3s 5ms/step - loss: 2.0361 - accuracy: 0.3246 - val_loss: 1.9979 - val_accuracy: 0.3509\nEpoch 10/10\n682/687 [============================>.] - ETA: 0s - loss: 1.9949 - accuracy: 0.3506\nEpoch 00010: val_loss improved from 1.99790 to 1.95068, saving model to C:\\Label.h5\n687/687 [==============================] - 4s 5ms/step - loss: 1.9944 - accuracy: 0.3508 - val_loss: 1.9507 - val_accuracy: 0.3358\n","name":"stdout"},{"output_type":"execute_result","execution_count":28,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f904037f310>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss,accuracy=model.evaluate(X_test,to_categorical(Y_test,number_of_labels+1))\nprint(\"Accuracy of the model with L2 , L1 and Dropout with earlyStopping and ReduceLrOnPlateau: \"+ str(accuracy))","execution_count":29,"outputs":[{"output_type":"stream","text":"225/225 [==============================] - 1s 3ms/step - loss: 2.2687 - accuracy: 0.3009\nAccuracy of the model with L2 , L1 and Dropout with earlyStopping and ReduceLrOnPlateau: 0.30089235305786133\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_tra=X_train.reshape(-1,784)\nX_tes=X_test.reshape(-1,784)","execution_count":30,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**AdaBoost Classifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nmodel = AdaBoostClassifier(random_state=1)\nmodel.fit(X_tra,Y_train)\n","execution_count":31,"outputs":[{"output_type":"execute_result","execution_count":31,"data":{"text/plain":"AdaBoostClassifier(random_state=1)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(X_tes,Y_test)","execution_count":32,"outputs":[{"output_type":"execute_result","execution_count":32,"data":{"text/plain":"0.31553262688232014"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"**XGBoost**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\nmodel_xgb = XGBClassifier()\nmodel_xgb.fit(X_tra, Y_train)\nmodel_xgb.score(X_tes,Y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}